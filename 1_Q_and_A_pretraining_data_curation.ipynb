{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q&A Data for Pretraining\n",
    "\n",
    "Load various NLP datasets and combine into a single source. This notebook outputs a 850mb text data file with 84M words/tokens with the following distribution:\n",
    "- 65% from wiki103\n",
    "- 18% from Tensorflow 2.0 Q&A\n",
    "- 17% from the StackSample dataset\n",
    "\n",
    "## Text datasets used\n",
    "\n",
    "- **[StackSample data](https://www.kaggle.com/stackoverflow/stacksample):** This is a dump of 10% of StackOverflow questions and answers, only answers with score > 7 were used to try and enfore some quality control on the relationship between question and answer\n",
    "\n",
    "- **[Kaggle Tensorflow 2.0 Q&A data](https://www.kaggle.com/c/tensorflow2-question-answering/data):** Q&A competition data from [Google's Natural Questions dataset](https://github.com/google-research-datasets/natural-questions/blob/master/README.md)\n",
    "\n",
    "- **[Wikitext-103](https://www.salesforce.com/products/einstein/ai-research/the-wikitext-dependency-language-modeling-dataset/):** A scrape of wikipedia articles, I used the \"raw\" version here\n",
    "\n",
    "## Data Processing\n",
    "I did my best to align the datasets as best I could. \n",
    "\n",
    "- Html was stripped\n",
    "- Wikipedia articles were combined based on the header sub-structure (\"=\" equals H1, \"==\" equals H2 etc)\n",
    "- Beginning and end of wikipedia article: `[BOS = 'xxars', EOS = 'xxare']`\n",
    "- Headers and sub-headers got a special token for start and end: `[H1S='xxh1s', H1e='xxh1e', H2S='xxh2s',H2e='xxh2e' etc..]`\n",
    "- Question Title, Body and Answers all got start and end tokens: `xxqts, xxqte, xxqbs, xxqbe, xxans, xxane`\n",
    "- Newline's were replaced with `xxnpg`\n",
    "\n",
    "\n",
    "## Thanks\n",
    "This [notebook from @xhlulu on Kaggle](https://www.kaggle.com/xhlulu/tf-qa-jsonl-to-dataframe) was super helpful in processing the TensorFlow 2.0 data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from fastai2.basics import *\n",
    "import gc\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HTML Stripper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from html.parser import HTMLParser\n",
    "\n",
    "class MLStripper(HTMLParser):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "        self.strict = False\n",
    "        self.convert_charrefs= True\n",
    "        self.fed = []\n",
    "    def handle_data(self, d):\n",
    "        self.fed.append(d)\n",
    "    def get_data(self):\n",
    "        return ''.join(self.fed)\n",
    "\n",
    "def strip_tags(html):\n",
    "    s = MLStripper()\n",
    "    s.feed(html)\n",
    "    return s.get_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Wiki data func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wiki(wiki_num: int=2, raw: bool=False):\n",
    "    if raw==True:\n",
    "        raw_p='-raw'\n",
    "        suff='raw'\n",
    "    else: \n",
    "        raw_p=''\n",
    "        suff='tokens'\n",
    "        \n",
    "    wiki_path = Path(f'data/wikitext-{wiki_num}{raw_p}')\n",
    "    \n",
    "    df_train = pd.read_csv(wiki_path/f'wiki.train.{suff}', sep='\\n', header=None)   \n",
    "    df_valid = pd.read_csv(wiki_path/f'wiki.valid.{suff}', sep='\\n', header=None)\n",
    "    df_test = pd.read_csv(wiki_path/f'wiki.test.{suff}', sep='\\n', header=None)\n",
    "\n",
    "    df_train.columns=['doc']\n",
    "    df_valid.columns=['doc']\n",
    "    df_test.columns=['doc']\n",
    "    \n",
    "    df_train['source'] = f'wiki{wiki_num}'\n",
    "    df_valid['source'] = f'wiki{wiki_num}'\n",
    "    df_test['source'] = f'wiki{wiki_num}'\n",
    "    \n",
    "    return df_train, df_valid, df_test "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean Wiki Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_wiki_header_toks(df_all):\n",
    "    \"\"\"Replace default wikitext header tokens (\"=\") with special tokens\"\"\"\n",
    "    df_all_cp = df_all.copy()\n",
    "\n",
    "    headers={i:'= '*i for i in range(7,0,-1)}\n",
    "\n",
    "    # Find the indexes that are likely to be headers\n",
    "    header_idxs=df_all.loc[df_all.doc.str.contains('\\=.*?\\=', regex=True)].index\n",
    "    \n",
    "    # Deal with sub-headers first\n",
    "    for h_i in range(7,1,-1):\n",
    "        mod_head_ls = []\n",
    "        mod_head_idx = []\n",
    "        df_all_cp.doc = df_all_cp.doc.str.replace(pat=headers[h_i], repl=f'xxh{h_i}s ')\n",
    "\n",
    "        # Replace all the end header tokens with a different one\n",
    "        for j, s in enumerate(df_all_cp.doc.values[header_idxs]):\n",
    "            if f'xxh{h_i}s' in s:\n",
    "                head, _sep, tail = s.rpartition(f'xxh{h_i}s ')    \n",
    "                mod_head_ls.append(f'{head} xxh{h_i}e {tail}')\n",
    "                mod_head_idx.append(header_idxs[j])\n",
    "\n",
    "        df_all_cp.doc.values[mod_head_idx] = mod_head_ls\n",
    "\n",
    "    # Deal with top level headers which are more tricky as there is only 1 \"=\"\"\n",
    "    mod_tail_ls = []\n",
    "    mod_tail_idx = []\n",
    "    for j, s in enumerate(df_all_cp.doc.values[header_idxs]):   \n",
    "        if s.endswith('= '):\n",
    "            # replace both = with H1s\n",
    "            uu = s.replace('=', 'xxh1s')\n",
    "\n",
    "            # Split by H1s and replace the last one with H1e\n",
    "            head, _sep, tail = uu.rpartition(f'xxh1s')   \n",
    "\n",
    "            mod_tail_ls.append(f'{head} xxh1e ')\n",
    "            mod_tail_idx.append(header_idxs[j])\n",
    "\n",
    "    df_all_cp.doc.values[mod_tail_idx] = mod_tail_ls\n",
    "\n",
    "    return df_all_cp, header_idxs\n",
    "\n",
    "\n",
    "def add_wiki_start_end(comp_ls, wiki_num):\n",
    "    ## Add start and end\n",
    "    BOS = 'xxars'\n",
    "    EOS = 'xxare'\n",
    "    H1S = 'xxh1s'\n",
    "    fin_dfs = []\n",
    "    \n",
    "    for df in comp_ls:\n",
    "\n",
    "        # Find the starting index for each article\n",
    "        art_starts = list(df.loc[df.doc.str.contains(pat=H1S, case=True, regex=False)].index)\n",
    "\n",
    "        new_arts = []\n",
    "        for i, idx in enumerate(art_starts[:-1]):\n",
    "            # Add Article Start and End Tokens\n",
    "            new_arts.append(BOS + df.loc[art_starts[i]:art_starts[i+1]-1].doc.str.cat(sep='xxnpg ') + EOS)\n",
    "\n",
    "        new_df = pd.DataFrame(new_arts, columns=['doc'])\n",
    "        new_df['source'] = f'wiki{wiki_num}'\n",
    "        new_df['char_count'] = new_df['doc'].str.len().values\n",
    "        \n",
    "        fin_dfs.append(new_df)\n",
    "    return fin_dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load StackSample data func\n",
    "\n",
    "- Only Answers with scores > 7 are loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ss_data(num_samples: int=5000):\n",
    "    ss_q = pd.read_csv('data/stacksample/Questions.csv', nrows=num_samples,\n",
    "                       usecols =['Id','Title', 'Body'],encoding='latin1')\n",
    "    ss_q = ss_q.dropna()\n",
    "\n",
    "    ss_a = pd.read_csv('data/stacksample/Answers.csv', nrows=num_samples,\n",
    "                       usecols =['ParentId','Body','Score'], encoding='latin1')\n",
    "    ss_a.columns = ['ParentId','Score','Answer_Body']\n",
    "    ss_a = ss_a.dropna()\n",
    "\n",
    "    # Merge Questions and Answers\n",
    "    ss_fin = pd.merge(left=ss_q, right=ss_a, left_on='Id', right_on='ParentId')\n",
    "\n",
    "    ss_fin = ss_fin.query('Score > 7').copy()\n",
    "    ss_fin.drop_duplicates(inplace=True)\n",
    "    \n",
    "    return ss_fin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean StackSample data func\n",
    "- Add question title, question body and answer body start and end tags\n",
    "- Merge question title, question body and answer to a single document\n",
    "- replace '\\ n' with xxnpg\n",
    "- Strip HTML as is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_ss_data(ss_fin):\n",
    "    # Add new paragraph tag (xxnpg)\n",
    "    ss_fin.Title = ss_fin.Title.str.replace(pat='\\n', repl=f' xxnpg ')\n",
    "    ss_fin.Body = ss_fin.Body.str.replace(pat='\\n', repl=f' xxnpg ')\n",
    "    ss_fin.Answer_Body = ss_fin.Answer_Body.str.replace(pat='\\n', repl=f' xxnpg ')\n",
    "\n",
    "    # Add start and end tags\n",
    "    ss_fin.Title = 'xxqts ' + ss_fin.Title.astype(str) + ' xxqte'\n",
    "    ss_fin.Body = 'xxqbs ' + ss_fin.Body.astype(str) + ' xxqbe'\n",
    "    ss_fin.Answer_Body = 'xxans ' + ss_fin.Answer_Body.astype(str) + ' xxane'\n",
    "\n",
    "    # Combine Question Title and Body and Answer Body to a single document\n",
    "    ss_fin['doc'] = ss_fin.Title.values + ' ' + ss_fin.Body.values + ' ' + ss_fin.Answer_Body.values\n",
    "    ss_fin = pd.DataFrame(ss_fin['doc'])\n",
    "\n",
    "    # Strip HTML tags\n",
    "    stripped = [strip_tags(t) for t in ss_fin['doc'].values]\n",
    "    \n",
    "    # Add some info\n",
    "    ss_fin['doc'] = stripped\n",
    "    ss_fin['source'] = 'stacksample'\n",
    "    #ss_fin['doc_type'] = 'qt_qb_a'\n",
    "    ss_fin['char_count'] = ss_fin['doc'].str.len().values\n",
    "    \n",
    "    return ss_fin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load TensorFlow 2.0 Q&A data (Google Natural Questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taken from https://www.kaggle.com/xhlulu/tf-qa-jsonl-to-dataframe\n",
    "def tf2qa_jsonl_to_df(file_path, n_rows=-1, load_annotations=True, truncate=True, offset=0):\n",
    "    \"\"\"\n",
    "    Simple utility function to load the .jsonl files for the \n",
    "    TF2.0 QA competition. It creates a dataframe of the dataset.\n",
    "    \n",
    "    To use, click \"File\" > \"Add utility script\", search the name of this \n",
    "    notebook, then run:\n",
    "    \n",
    "    >>> from tf_qa_jsonl_to_dataframe import jsonl_to_df\n",
    "    >>> train = jsonl_to_df(\"/kaggle/...train.jsonl\")\n",
    "    >>> test = jsonl_to_df(\"/kaggle/...test.jsonl\", load_annotations=False)\n",
    "    \n",
    "    Parameters:\n",
    "        * file_path (str): The path to your json_file.\n",
    "        * n_rows (int): The number of rows you are importing. Set value to -1 if you want to import everything. [Default=-1]\n",
    "        * load_annotations (bool): Whether to load annotations (for training data) or not (test set does not have\n",
    "          annotations). [Default=True]\n",
    "        * truncate (bool): Whether to cut the text before the first answer (long or short) [Default=True]\n",
    "          and after the last answer (long or short), leaving a space for the offset\n",
    "        * offset (int): If offset = k, then keep only keep the interval (answer_start - k, answer_end + k) [Default=True]\n",
    "        \n",
    "    Returns:\n",
    "        A Dataframe containing the following columns:\n",
    "            * document_text (str): The document split by whitespace, possibly truncated\n",
    "            * question_text (str): the question posed\n",
    "            * yes_no_answer (str): Could be \"YES\", \"NO\", or \"NONE\"\n",
    "            * short_answer_start (int): Start index of token, -1 if does not exist\n",
    "            * short_answer_end (int): End index of token, -1 if does not exist\n",
    "            * long_answer_start (int): Start index of token, -1 if does not exist\n",
    "            * long_answer_end (int): End index of token, -1 if does not exist\n",
    "            * example_id (str): ID representing the string.\n",
    "    \n",
    "    Author: @xhlulu\n",
    "    Source: https://www.kaggle.com/xhlulu/tf-qa-jsonl-to-dataframe\n",
    "    \"\"\"\n",
    "    json_lines = []\n",
    "    \n",
    "    with open(file_path) as f:\n",
    "        for i, line in tqdm(enumerate(f)):\n",
    "            if i == n_rows:\n",
    "                break\n",
    "            \n",
    "            line = json.loads(line)\n",
    "            last_token = line['long_answer_candidates'][-1]['end_token']\n",
    "\n",
    "            out_di = {\n",
    "                'document_text': line['document_text'],\n",
    "                'question_text': line['question_text']\n",
    "            }\n",
    "            \n",
    "            if 'example_id' in line:\n",
    "                out_di['example_id'] = line['example_id']\n",
    "            \n",
    "            if load_annotations:\n",
    "                annot = line['annotations'][0]\n",
    "                \n",
    "                out_di['yes_no_answer'] = annot['yes_no_answer']\n",
    "                out_di['long_answer_start'] = annot['long_answer']['start_token']\n",
    "                out_di['long_answer_end'] = annot['long_answer']['end_token']\n",
    "\n",
    "                if len(annot['short_answers']) > 0:\n",
    "                    out_di['short_answer_start'] = annot['short_answers'][0]['start_token']\n",
    "                    out_di['short_answer_end'] = annot['short_answers'][0]['end_token']\n",
    "                else:\n",
    "                    out_di['short_answer_start'] = -1\n",
    "                    out_di['short_answer_end'] = -1\n",
    "\n",
    "                if truncate:\n",
    "                    if out_di['long_answer_start'] == -1:\n",
    "                        start_threshold = out_di['short_answer_start'] - offset\n",
    "                    elif out_di['short_answer_start'] == -1:\n",
    "                        start_threshold = out_di['long_answer_start'] - offset\n",
    "                    else:\n",
    "                        start_threshold = min(out_di['long_answer_start'], out_di['short_answer_start']) - offset\n",
    "                        \n",
    "                    start_threshold = max(0, start_threshold)\n",
    "                    end_threshold = max(out_di['long_answer_end'], out_di['short_answer_end']) + offset + 1\n",
    "                    \n",
    "                    out_di['document_text'] = \" \".join(\n",
    "                        out_di['document_text'].split(' ')[start_threshold:end_threshold]\n",
    "                    )\n",
    "\n",
    "            json_lines.append(out_di)\n",
    "\n",
    "    df = pd.DataFrame(json_lines).fillna(-1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean TensorFlow 2.0 Q&A data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tf2qa_data(tf2qa_data):\n",
    "    # Remove articles without long answer\n",
    "    tf2qa_data = tf2qa_data.loc[tf2qa_data['long_answer_start'] != -1, ['question_text', 'document_text']]\n",
    "\n",
    "    # Add question mark and Question start and end tags to the end of each question\n",
    "    tf2qa_data['question_text'] = 'xxqbs ' + tf2qa_data['question_text'].values + '?' + ' xxqbe'\n",
    "\n",
    "    # Add Answer start and end tags\n",
    "    tf2qa_data['document_text'] = 'xxans ' + tf2qa_data['document_text'] + ' xxane'\n",
    "\n",
    "    # Merge to a single doc\n",
    "    tf2qa_data['doc'] = tf2qa_data['question_text'] + ' ' + tf2qa_data['document_text']\n",
    "\n",
    "    # Strip HTML\n",
    "    tf2qa_data['doc'] = [strip_tags(t) for t in tf2qa_data['doc'].values]\n",
    "    \n",
    "    tf2qa_data_fin= pd.DataFrame(tf2qa_data['doc'].values, columns=['doc'])\n",
    "    \n",
    "    # Add some source info\n",
    "    tf2qa_data_fin['source'] = 'tf2qa'\n",
    "\n",
    "    # Add character count\n",
    "    tf2qa_data_fin['char_count'] = tf2qa_data_fin['doc'].str.len().values\n",
    "    return tf2qa_data_fin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data\n",
    "#### Load Wiki Data\n",
    "- Option to either load wiki2 or wiki103, with the raw or tokenized versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded\n",
      "Header toks added\n",
      "Start, end toks added\n",
      "Short articles discarded\n",
      "28784 546080745\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc</th>\n",
       "      <th>source</th>\n",
       "      <th>char_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xxars xxh1s Valkyria Chronicles III  xxh1e xxnpg  Senjō no Valkyria 3 : Unrecorded Chronicles ( Japanese : 戦場のヴァルキュリア3 , lit . Valkyria of the Battlefield 3 ) , commonly referred to as Valkyria Chronicles III outside Japan , is a tactical role @-@ playing video game developed by Sega and Media.Vision for the PlayStation Portable . Released in January 2011 in Japan , it is the third game in the Valkyria series . Employing the same fusion of tactical and real @-@ time gameplay as its predecessors , the story runs parallel to the first game and follows the \" Nameless \" , a penal military unit...</td>\n",
       "      <td>wiki103</td>\n",
       "      <td>21104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xxars xxh1s Tower Building of the Little Rock Arsenal  xxh1e xxnpg  The Tower Building of the Little Rock Arsenal , also known as U.S. Arsenal Building , is a building located in MacArthur Park in downtown Little Rock , Arkansas . Built in 1840 , it was part of Little Rock 's first military installation . Since its decommissioning , The Tower Building has housed two museums . It was home to the Arkansas Museum of Natural History and Antiquities from 1942 to 1997 and the MacArthur Museum of Arkansas Military History since 2001 . It has also been the headquarters of the Little Rock Æsthetic ...</td>\n",
       "      <td>wiki103</td>\n",
       "      <td>21870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xxars xxh1s Cicely Mary Barker  xxh1e xxnpg  Cicely Mary Barker ( 28 June 1895 – 16 February 1973 ) was an English illustrator best known for a series of fantasy illustrations depicting fairies and flowers . Barker 's art education began in girlhood with correspondence courses and instruction at the Croydon School of Art . Her earliest professional work included greeting cards and juvenile magazine illustrations , and her first book , Flower Fairies of the Spring , was published in 1923 . Similar books were published in the following decades . xxnpg  Barker was a devout Anglican , and dona...</td>\n",
       "      <td>wiki103</td>\n",
       "      <td>16713</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       doc  \\\n",
       "0  xxars xxh1s Valkyria Chronicles III  xxh1e xxnpg  Senjō no Valkyria 3 : Unrecorded Chronicles ( Japanese : 戦場のヴァルキュリア3 , lit . Valkyria of the Battlefield 3 ) , commonly referred to as Valkyria Chronicles III outside Japan , is a tactical role @-@ playing video game developed by Sega and Media.Vision for the PlayStation Portable . Released in January 2011 in Japan , it is the third game in the Valkyria series . Employing the same fusion of tactical and real @-@ time gameplay as its predecessors , the story runs parallel to the first game and follows the \" Nameless \" , a penal military unit...   \n",
       "1  xxars xxh1s Tower Building of the Little Rock Arsenal  xxh1e xxnpg  The Tower Building of the Little Rock Arsenal , also known as U.S. Arsenal Building , is a building located in MacArthur Park in downtown Little Rock , Arkansas . Built in 1840 , it was part of Little Rock 's first military installation . Since its decommissioning , The Tower Building has housed two museums . It was home to the Arkansas Museum of Natural History and Antiquities from 1942 to 1997 and the MacArthur Museum of Arkansas Military History since 2001 . It has also been the headquarters of the Little Rock Æsthetic ...   \n",
       "2  xxars xxh1s Cicely Mary Barker  xxh1e xxnpg  Cicely Mary Barker ( 28 June 1895 – 16 February 1973 ) was an English illustrator best known for a series of fantasy illustrations depicting fairies and flowers . Barker 's art education began in girlhood with correspondence courses and instruction at the Croydon School of Art . Her earliest professional work included greeting cards and juvenile magazine illustrations , and her first book , Flower Fairies of the Spring , was published in 1923 . Similar books were published in the following decades . xxnpg  Barker was a devout Anglican , and dona...   \n",
       "\n",
       "    source  char_count  \n",
       "0  wiki103       21104  \n",
       "1  wiki103       21870  \n",
       "2  wiki103       16713  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "wiki_num = 103\n",
    "wiki_train, wiki_valid, wiki_test = get_wiki(wiki_num=wiki_num, raw=True)\n",
    "print('Data loaded')\n",
    "\n",
    "# Add header toks\n",
    "wiki_dfs = [wiki_train, wiki_valid, wiki_test]\n",
    "comb_ls = []\n",
    "for df in wiki_dfs:\n",
    "    new_df, header_idxs = add_wiki_header_toks(df)\n",
    "    comb_ls.append(new_df)\n",
    "print('Header toks added')\n",
    "\n",
    "# Add start and end articles\n",
    "wiki_tmp_dfs = add_wiki_start_end(comb_ls, wiki_num)\n",
    "print('Start, end toks added')\n",
    "# Remove short articles, less than 2000 characters\n",
    "# The below commented out code shows the distribution of character lengths\n",
    "# import matplotlib.pyplot as plt\n",
    "# bins=[]\n",
    "# for h in range(0,10000, 200):\n",
    "#     bins.append(h)\n",
    "# plt.hist(wiki_fin_df['doc'].str.len(),bins=bins)\n",
    "\n",
    "def cut_short_wikis(df):\n",
    "    df = df[df['doc'].str.len() > 2000]\n",
    "    return df\n",
    "    \n",
    "# Split df ls and tidy up\n",
    "wiki_train_fin_df=cut_short_wikis(wiki_tmp_dfs[0])\n",
    "wiki_valid_fin_df=cut_short_wikis(wiki_tmp_dfs[1])\n",
    "wiki_test_fin_df=cut_short_wikis(wiki_tmp_dfs[2])\n",
    "print('Short articles discarded')\n",
    "\n",
    "wiki_fin_df = pd.concat([wiki_train_fin_df, wiki_valid_fin_df])\n",
    "wiki_fin_df.reset_index(drop=True, inplace=True)\n",
    "#wiki_fin_df['char_count'] = wiki_fin_df['doc'].str.len().values\n",
    "\n",
    "wiki_test_fin_df.reset_index(drop=True, inplace=True)\n",
    "#wiki_test_fin_df['char_count'] = wiki_test_fin_df['doc'].str.len().values\n",
    "\n",
    "print(len(wiki_fin_df), wiki_fin_df.char_count.sum())\n",
    "wiki_fin_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load StackSample Q&A data (from Stackoverflow)\n",
    "\n",
    "- Source https://www.kaggle.com/stackoverflow/stacksample/tasks\n",
    "- 2M Q&A Pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79704 147225545\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc</th>\n",
       "      <th>source</th>\n",
       "      <th>char_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xxqts SQLStatement.execute() - multiple queries in one statement xxqte xxqbs I've written a database generation script in SQL and want to execute it in my Adobe AIR application: xxnpg  xxnpg Create Table tRole ( xxnpg       roleID integer Primary Key xxnpg       ,roleName varchar(40) xxnpg ); xxnpg Create Table tFile ( xxnpg     fileID integer Primary Key xxnpg     ,fileName varchar(50) xxnpg     ,fileDescription varchar(500) xxnpg     ,thumbnailID integer xxnpg     ,fileFormatID integer xxnpg     ,categoryID integer xxnpg     ,isFavorite boolean xxnpg     ,dateAdded date xxnpg     ,global...</td>\n",
       "      <td>stacksample</td>\n",
       "      <td>2620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>xxqts Good branching and merging tutorials for TortoiseSVN? xxqte xxqbs Are there any really good tutorials explaining branching and merging with Apache Subversion?  xxnpg  xxnpg All the better if it's specific to TortoiseSVN client. xxnpg  xxqbe xxans Version Control with Subversion\\r xxnpg \\r xxnpg A very good resource for source control in general. Not really TortoiseSVN specific, though. xxane</td>\n",
       "      <td>stacksample</td>\n",
       "      <td>398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>xxqts Good branching and merging tutorials for TortoiseSVN? xxqte xxqbs Are there any really good tutorials explaining branching and merging with Apache Subversion?  xxnpg  xxnpg All the better if it's specific to TortoiseSVN client. xxnpg  xxqbe xxans My easy click-by-click instructions (specific to TortoiseSVN) are in Stack Overflow question What is the simplest way to do branching and merging using TortoiseSVN?. xxnpg  xxane</td>\n",
       "      <td>stacksample</td>\n",
       "      <td>431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>xxqts ASP.NET Site Maps xxqte xxqbs Has anyone got experience creating SQL-based ASP.NET site-map providers? xxnpg  xxnpg I've got the default XML file web.sitemap working properly with my Menu and SiteMapPath controls, but I'll need a way for the users of my site to create and modify pages dynamically. xxnpg  xxnpg I need to tie page viewing permissions into the standard ASP.NET membership system as well. xxnpg  xxqbe xxans The Jeff Prosise version from MSDN magazine works pretty well, but it has a few flaws: xxnpg  xxnpg AddNode freaks out with links to external sites on your menu (www.g...</td>\n",
       "      <td>stacksample</td>\n",
       "      <td>1772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>xxqts Function for creating color wheels xxqte xxqbs This is something I've pseudo-solved many times and never quite found a solution. That's stuck with me. The problem is to come up with a way to generate N colors, that are as distinguishable as possible where N is a parameter. xxnpg  xxqbe xxans My first thought on this is \"how generate N vectors in a space that maximize distance from each other.\" You can see that the RGB (or any other scale you use that forms a basis in color space) are just vectors. Take a look at Random Point Picking. Hope this is a good start for you! Once you have a...</td>\n",
       "      <td>stacksample</td>\n",
       "      <td>1353</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       doc  \\\n",
       "0  xxqts SQLStatement.execute() - multiple queries in one statement xxqte xxqbs I've written a database generation script in SQL and want to execute it in my Adobe AIR application: xxnpg  xxnpg Create Table tRole ( xxnpg       roleID integer Primary Key xxnpg       ,roleName varchar(40) xxnpg ); xxnpg Create Table tFile ( xxnpg     fileID integer Primary Key xxnpg     ,fileName varchar(50) xxnpg     ,fileDescription varchar(500) xxnpg     ,thumbnailID integer xxnpg     ,fileFormatID integer xxnpg     ,categoryID integer xxnpg     ,isFavorite boolean xxnpg     ,dateAdded date xxnpg     ,global...   \n",
       "3                                                                                                                                                                                                         xxqts Good branching and merging tutorials for TortoiseSVN? xxqte xxqbs Are there any really good tutorials explaining branching and merging with Apache Subversion?  xxnpg  xxnpg All the better if it's specific to TortoiseSVN client. xxnpg  xxqbe xxans Version Control with Subversion\\r xxnpg \\r xxnpg A very good resource for source control in general. Not really TortoiseSVN specific, though. xxane   \n",
       "5                                                                                                                                                                          xxqts Good branching and merging tutorials for TortoiseSVN? xxqte xxqbs Are there any really good tutorials explaining branching and merging with Apache Subversion?  xxnpg  xxnpg All the better if it's specific to TortoiseSVN client. xxnpg  xxqbe xxans My easy click-by-click instructions (specific to TortoiseSVN) are in Stack Overflow question What is the simplest way to do branching and merging using TortoiseSVN?. xxnpg  xxane   \n",
       "6  xxqts ASP.NET Site Maps xxqte xxqbs Has anyone got experience creating SQL-based ASP.NET site-map providers? xxnpg  xxnpg I've got the default XML file web.sitemap working properly with my Menu and SiteMapPath controls, but I'll need a way for the users of my site to create and modify pages dynamically. xxnpg  xxnpg I need to tie page viewing permissions into the standard ASP.NET membership system as well. xxnpg  xxqbe xxans The Jeff Prosise version from MSDN magazine works pretty well, but it has a few flaws: xxnpg  xxnpg AddNode freaks out with links to external sites on your menu (www.g...   \n",
       "9  xxqts Function for creating color wheels xxqte xxqbs This is something I've pseudo-solved many times and never quite found a solution. That's stuck with me. The problem is to come up with a way to generate N colors, that are as distinguishable as possible where N is a parameter. xxnpg  xxqbe xxans My first thought on this is \"how generate N vectors in a space that maximize distance from each other.\" You can see that the RGB (or any other scale you use that forms a basis in color space) are just vectors. Take a look at Random Point Picking. Hope this is a good start for you! Once you have a...   \n",
       "\n",
       "        source  char_count  \n",
       "0  stacksample        2620  \n",
       "3  stacksample         398  \n",
       "5  stacksample         431  \n",
       "6  stacksample        1772  \n",
       "9  stacksample        1353  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_samples = 1000000\n",
    "ss_fin = load_ss_data(num_samples)\n",
    "ss_fin = clean_ss_data(ss_fin)\n",
    "\n",
    "print(len(ss_fin), ss_fin.char_count.sum())\n",
    "ss_fin.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load TensorFlow 2.0 Q&A 2.0 data \n",
    "\n",
    "- From Google Natural Questions dataset\n",
    "\n",
    "- https://www.kaggle.com/c/tensorflow2-question-answering/data\n",
    "\n",
    "- https://github.com/google-research-datasets/natural-questions\n",
    "\n",
    "- https://storage.googleapis.com/pub-tools-public-publication-data/pdf/1f7b46b5378d757553d3e92ead36bda2e4254244.pdf\n",
    "\n",
    "The NQ training data contains 307,373 examples. 152,148 have a long answer and 110,724 have a short answer. Short answers can be sets of spans in the document (106,926), or yes or no (3,798). Long answers are HTML bounding boxes.\n",
    "\n",
    "- Filtered for Long Answers only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "199824it [02:10, 1697.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99093 153611999\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc</th>\n",
       "      <th>source</th>\n",
       "      <th>char_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xxqbs which is the most common use of opt-in e-mail marketing? xxqbe xxans  A common example of permission marketing is a newsletter sent to an advertising firm 's customers . Such newsletters inform customers of upcoming events or promotions , or new products . In this type of advertising , a company that wants to send a newsletter to their customers may ask them at the point of purchase if they would like to receive the newsletter .   xxane</td>\n",
       "      <td>tf2qa</td>\n",
       "      <td>446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xxqbs how i.met your mother who is the mother? xxqbe xxans  Tracy McConnell , better known as `` The Mother '' , is the title character from the CBS television sitcom How I Met Your Mother . The show , narrated by Future Ted , tells the story of how Ted Mosby met The Mother . Tracy McConnell appears in 8 episodes from `` Lucky Penny '' to `` The Time Travelers '' as an unseen character ; she was first seen fully in `` Something New '' and was promoted to a main character in season 9 . The Mother is played by Cristin Milioti .   xxane</td>\n",
       "      <td>tf2qa</td>\n",
       "      <td>539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xxqbs what type of fertilisation takes place in humans? xxqbe xxans  The process of fertilization involves a sperm fusing with an ovum . The most common sequence begins with ejaculation during copulation , follows with ovulation , and finishes with fertilization . Various exceptions to this sequence are possible , including artificial insemination , in vitro fertilization , external ejaculation without copulation , or copulation shortly after ovulation . Upon encountering the secondary oocyte , the acrosome of the sperm produces enzymes which allow it to burrow through the outer jelly coat...</td>\n",
       "      <td>tf2qa</td>\n",
       "      <td>791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>xxqbs who had the most wins in the nfl? xxqbe xxans  Active quarterback Tom Brady holds the records for most wins with 220 , most regular season wins with 195 , and most postseason wins with 25 , as of Week 16 of the 2017 NFL season . Having played the entirety of his career with the New England Patriots , each of Brady 's win records also apply to wins with a single team .   xxane</td>\n",
       "      <td>tf2qa</td>\n",
       "      <td>384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>xxqbs who played mantis guardians of the galaxy 2? xxqbe xxans  Pom Klementieff ( born 3 May 1986 ) is a French actress . She was trained at the Cours Florent drama school in Paris and has appeared in such films as Loup ( 2009 ) , Sleepless Night ( 2011 ) and Hacker 's Game ( 2015 ) . She plays the role of Mantis in the film Guardians of the Galaxy Vol. 2 ( 2017 ) and will appear in the same role in the film Avengers : Infinity War ( 2018 ) .   xxane</td>\n",
       "      <td>tf2qa</td>\n",
       "      <td>454</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       doc  \\\n",
       "0                                                                                                                                                           xxqbs which is the most common use of opt-in e-mail marketing? xxqbe xxans  A common example of permission marketing is a newsletter sent to an advertising firm 's customers . Such newsletters inform customers of upcoming events or promotions , or new products . In this type of advertising , a company that wants to send a newsletter to their customers may ask them at the point of purchase if they would like to receive the newsletter .   xxane   \n",
       "1                                                              xxqbs how i.met your mother who is the mother? xxqbe xxans  Tracy McConnell , better known as `` The Mother '' , is the title character from the CBS television sitcom How I Met Your Mother . The show , narrated by Future Ted , tells the story of how Ted Mosby met The Mother . Tracy McConnell appears in 8 episodes from `` Lucky Penny '' to `` The Time Travelers '' as an unseen character ; she was first seen fully in `` Something New '' and was promoted to a main character in season 9 . The Mother is played by Cristin Milioti .   xxane   \n",
       "2  xxqbs what type of fertilisation takes place in humans? xxqbe xxans  The process of fertilization involves a sperm fusing with an ovum . The most common sequence begins with ejaculation during copulation , follows with ovulation , and finishes with fertilization . Various exceptions to this sequence are possible , including artificial insemination , in vitro fertilization , external ejaculation without copulation , or copulation shortly after ovulation . Upon encountering the secondary oocyte , the acrosome of the sperm produces enzymes which allow it to burrow through the outer jelly coat...   \n",
       "3                                                                                                                                                                                                                         xxqbs who had the most wins in the nfl? xxqbe xxans  Active quarterback Tom Brady holds the records for most wins with 220 , most regular season wins with 195 , and most postseason wins with 25 , as of Week 16 of the 2017 NFL season . Having played the entirety of his career with the New England Patriots , each of Brady 's win records also apply to wins with a single team .   xxane   \n",
       "4                                                                                                                                                   xxqbs who played mantis guardians of the galaxy 2? xxqbe xxans  Pom Klementieff ( born 3 May 1986 ) is a French actress . She was trained at the Cours Florent drama school in Paris and has appeared in such films as Loup ( 2009 ) , Sleepless Night ( 2011 ) and Hacker 's Game ( 2015 ) . She plays the role of Mantis in the film Guardians of the Galaxy Vol. 2 ( 2017 ) and will appear in the same role in the film Avengers : Infinity War ( 2018 ) .   xxane   \n",
       "\n",
       "  source  char_count  \n",
       "0  tf2qa         446  \n",
       "1  tf2qa         539  \n",
       "2  tf2qa         791  \n",
       "3  tf2qa         384  \n",
       "4  tf2qa         454  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf2qa_data = tf2qa_jsonl_to_df('data/tensorflow2-question-answering/simplified-nq-train.jsonl', n_rows=200000, offset=0)\n",
    "tf2qa_fin = clean_tf2qa_data(tf2qa_data)\n",
    "\n",
    "print(len(tf2qa_fin), tf2qa_fin.char_count.sum())\n",
    "tf2qa_fin.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows : 207581\n",
      "Total character count : 846918289\n",
      "NaNs in doc column: 0.0\n",
      "File size is 0.855439529GB\n",
      "\n",
      "             char_count\n",
      "source                 \n",
      "stacksample    0.173837\n",
      "tf2qa          0.181378\n",
      "wiki103        0.644786\n",
      "\n",
      "data/lm_data_2020-02-04.csv\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc</th>\n",
       "      <th>source</th>\n",
       "      <th>char_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>115117</th>\n",
       "      <td>xxqbs when did man on the moon come out? xxqbe xxans    Man on the Moon     Theatrical release poster     Directed by   Miloš Forman     Produced by     Danny DeVito   Michael Shamberg   Stacey Sher       Written by     Scott Alexander   Larry Karaszewski       Starring     Jim Carrey   Danny DeVito   Courtney Love   Paul Giamatti       Music by   R.E.M.     Cinematography   Anastas N. Michos     Edited by     Adam Boome   Lynzee Klingman   Christopher Tellefsen       Production companies     BBC Films   Cinehaus   Jersey Films   Marubeni   Mutual Film Company   Shapiro / West Productions ...</td>\n",
       "      <td>tf2qa</td>\n",
       "      <td>921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23261</th>\n",
       "      <td>xxars xxh1s Wendell Willkie  xxh1e xxnpg  Wendell Lewis Willkie ( born Lewis Wendell Willkie ; February 18 , 1892 – October 8 , 1944 ) was an American lawyer , corporate executive , and the 1940 Republican candidate for president . Willkie appealed to many convention delegates as the Republican field 's only interventionist : although the U.S. remained neutral prior to Pearl Harbor , he favored greater U.S. involvement in World War II to support Britain and other Allies . His Democratic opponent , incumbent President Franklin D. Roosevelt , won the 1940 election with roughly 55 % of the po...</td>\n",
       "      <td>wiki103</td>\n",
       "      <td>68081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27841</th>\n",
       "      <td>xxars xxh1s Coming Up to Breathe  xxh1e xxnpg  Coming Up to Breathe is the fourth studio album by Christian rock band MercyMe . Released on April 25 , 2006 , by INO Records , the album was intended by MercyMe to be edgier than their previous albums . Coming Up to Breathe sold 58 @,@ 000 copies its first week , MercyMe 's biggest sales week at the time . It debuted and peaked at number one on the Billboard Christian Albums chart , number five on the Rock Albums chart , and number thirteen on the Billboard 200 . It also appeared on the Alternative Albums chart in 2007 , peaking at number thi...</td>\n",
       "      <td>wiki103</td>\n",
       "      <td>10414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67891</th>\n",
       "      <td>xxqts Add a column if it doesn't exist to all tables? xxqte xxqbs I'm using SQL Server 2005/2008.  I need to add a column to a table if it does not yet exist. This will apply to all tables in a given database.  I hoped I was close, but I'm having issues with this solution. xxnpg  xxnpg How can this be done? xxnpg  xxnpg Here's what I have: xxnpg  xxnpg EXEC sp_MSforeachtable ' xxnpg     declare @tblname varchar(255); xxnpg     SET @tblname =  PARSENAME(\"?\",1); xxnpg  xxnpg     if not exists (select column_name from INFORMATION_SCHEMA.columns  xxnpg                    where table_name = @tb...</td>\n",
       "      <td>stacksample</td>\n",
       "      <td>1633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128752</th>\n",
       "      <td>xxqbs why did new zealand soldiers go to world war 1? xxqbe xxans  The military history of New Zealand during World War I began in August 1914 when Great Britain declared war on Germany at the start of the First World War , the New Zealand government followed without hesitation , despite its geographic isolation and small population . It was believed at the time that any declaration of war by the United Kingdom automatically included New Zealand .   xxane</td>\n",
       "      <td>tf2qa</td>\n",
       "      <td>459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156442</th>\n",
       "      <td>xxqbs identify the demographic groups that made up the new reagan coalition? xxqbe xxans    VOTER GROUPS AND THE PRESIDENTIAL VOTE , 1980 AND 1976       Size   ' 80 Carter   ' 80 Reagan   ' 80 Anderson   ' 76 Carter   ' 76 Ford     Party                 Democratic   43   66   26   6   77   22     Independent   23   30   54   12   43   54     Republican   28   11   84     9   90     Ideology                 Liberal   18   57   27   11   70   26     Moderate   51   42   48   8   51   48     Conservative   31   23   71     29   70     Race                 Black   10   82   14     82   16     ...</td>\n",
       "      <td>tf2qa</td>\n",
       "      <td>2606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29089</th>\n",
       "      <td>xxqts Factorial Algorithms in different languages xxqte xxqbs I want to see all the different ways you can come up with, for a factorial subroutine, or program. The hope is that anyone can come here and see if they might want to learn a new language. xxnpg  xxnpg Ideas: xxnpg  xxnpg  xxnpg Procedural xxnpg Functional xxnpg Object Oriented xxnpg One liners xxnpg Obfuscated xxnpg Oddball xxnpg Bad Code xxnpg Polyglot xxnpg  xxnpg  xxnpg Basically I want to see an example, of different ways of writing an algorithm, and what they would look like in different languages. xxnpg  xxnpg Please limi...</td>\n",
       "      <td>stacksample</td>\n",
       "      <td>1644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170018</th>\n",
       "      <td>xxqbs where does the last name polanco originate from? xxqbe xxans  Polanco is a Spanish surname originating from the municipality of Polanco , Cantabria in Spain . Notable people with the surname include :   xxane</td>\n",
       "      <td>tf2qa</td>\n",
       "      <td>214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130324</th>\n",
       "      <td>xxqbs history of garden of the gods colorado springs? xxqbe xxans  The Garden of the Gods ' red rock formations were created during a geological upheaval along a natural fault line millions of years ago . Archaeological evidence shows that prehistoric people visited Garden of the Gods about 1330 BC . At about 250 BC , Native American people camped in the park ; they are believed to have been attracted to wildlife and plant life in the area and used overhangs created by the rocks for shelter . Many native peoples have reported a connection to Garden of the Gods , including Apache , Cheyenne...</td>\n",
       "      <td>tf2qa</td>\n",
       "      <td>671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129605</th>\n",
       "      <td>xxqbs who does miss rabbit's voice on peppa pig? xxqbe xxans  Sarah Ann Kennedy is a British voice actress best known for providing the voices of Miss Rabbit and Mummy Rabbit in the children 's animated series Peppa Pig , Nanny Plum in the children 's animated series Ben &amp; Holly 's Little Kingdom and Dolly Pond in Pond Life . She is also a writer and animation director and the creator of Crapston Villas , an animated soap opera for Channel 4 in 1996 -- 1998 . She has also written for Hit Entertainment and Peppa Pig , and is a lecturer at the University of Central Lancashire .   xxane</td>\n",
       "      <td>tf2qa</td>\n",
       "      <td>590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107547</th>\n",
       "      <td>xxqts li:hover - is it possible to change language of text? xxqte xxqbs A bit of a weird one,  xxnpg  xxnpg I know some of you might ask why, but I was wondering if you could change the language of some links once the user hovers over them? xxnpg  xxnpg nav li:hover { xxnpg    **change language here** xxnpg } xxnpg  xxnpg  xxnpg I was actually looking to convert English to Japanese, I'm assuming this isn't done with CSS, anyone have any ideas on how I'd go about this? xxnpg  xxnpg thanks xxnpg  xxqbe xxans You can do it with javascript, but a CSS only implementation could be like so: xxnpg...</td>\n",
       "      <td>stacksample</td>\n",
       "      <td>1038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156549</th>\n",
       "      <td>xxqbs who is the president of the senate in nigeria? xxqbe xxans  The President of the Senate is the presiding officer of the Senate of Nigeria , elected by its membership . The Senate President is second in line for succession to the Nigerian presidency , after the Vice President of Nigeria . The current President of the Senate is Bukola Saraki .   xxane</td>\n",
       "      <td>tf2qa</td>\n",
       "      <td>357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133627</th>\n",
       "      <td>xxqbs when is a medical student considered a doctor? xxqbe xxans  Upon successful completion of medical school , students are granted the title of Doctor of Medicine ( M.D. ) or Doctor of Osteopathic Medicine ( D.O. ) . Residency training , which is a supervised training period of three to seven years ( usually incorporating the 1st year internship ) typically completed for specific areas of specialty . Physicians who sub-specialize or who desire more supervised experience may complete a fellowship , which is an additional one to four years of supervised training in their area of expertise...</td>\n",
       "      <td>tf2qa</td>\n",
       "      <td>606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184100</th>\n",
       "      <td>xxqbs who played violet in saved by the bell? xxqbe xxans  Screech does eventually end up with a girlfriend , Violet Anne Bickerstaff ( played by the then unknown Tori Spelling ) , and dates her for several episodes , even managing to win back the support of her upper - class parents after losing it on a disastrous dinner date . Violet is then never seen again , without any explanation .   xxane</td>\n",
       "      <td>tf2qa</td>\n",
       "      <td>398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109927</th>\n",
       "      <td>xxqbs last briton to reach mens finals at wimbledon? xxqbe xxans    Year   Best British Finish   Player   Last Opponent   Score in last match     1968   Fourth round   Mark Cox   Rod Laver   9 - 7 , 5 - 7 , 6 - 2 , 6 - 0     1969   Fourth round   Robert Wilson   Tom Okker   11 - 9 , 6 - 4 , 6 - 2     1970   Semi-final   Roger Taylor   Ken Rosewall   6 - 3 , 4 - 6 , 6 - 3 , 6 - 3     1971   Third round   Gerald Battrick   John Newcombe   6 - 4 , 6 - 4 , 6 - 4     1972   Third round   John Paish   Alex Metreveli   7 - 5 , 6 - 3 , 3 - 6 , 6 - 4     1973   Semi-final   Roger Taylor   Jan Kodeš...</td>\n",
       "      <td>tf2qa</td>\n",
       "      <td>5223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            doc  \\\n",
       "115117  xxqbs when did man on the moon come out? xxqbe xxans    Man on the Moon     Theatrical release poster     Directed by   Miloš Forman     Produced by     Danny DeVito   Michael Shamberg   Stacey Sher       Written by     Scott Alexander   Larry Karaszewski       Starring     Jim Carrey   Danny DeVito   Courtney Love   Paul Giamatti       Music by   R.E.M.     Cinematography   Anastas N. Michos     Edited by     Adam Boome   Lynzee Klingman   Christopher Tellefsen       Production companies     BBC Films   Cinehaus   Jersey Films   Marubeni   Mutual Film Company   Shapiro / West Productions ...   \n",
       "23261   xxars xxh1s Wendell Willkie  xxh1e xxnpg  Wendell Lewis Willkie ( born Lewis Wendell Willkie ; February 18 , 1892 – October 8 , 1944 ) was an American lawyer , corporate executive , and the 1940 Republican candidate for president . Willkie appealed to many convention delegates as the Republican field 's only interventionist : although the U.S. remained neutral prior to Pearl Harbor , he favored greater U.S. involvement in World War II to support Britain and other Allies . His Democratic opponent , incumbent President Franklin D. Roosevelt , won the 1940 election with roughly 55 % of the po...   \n",
       "27841   xxars xxh1s Coming Up to Breathe  xxh1e xxnpg  Coming Up to Breathe is the fourth studio album by Christian rock band MercyMe . Released on April 25 , 2006 , by INO Records , the album was intended by MercyMe to be edgier than their previous albums . Coming Up to Breathe sold 58 @,@ 000 copies its first week , MercyMe 's biggest sales week at the time . It debuted and peaked at number one on the Billboard Christian Albums chart , number five on the Rock Albums chart , and number thirteen on the Billboard 200 . It also appeared on the Alternative Albums chart in 2007 , peaking at number thi...   \n",
       "67891   xxqts Add a column if it doesn't exist to all tables? xxqte xxqbs I'm using SQL Server 2005/2008.  I need to add a column to a table if it does not yet exist. This will apply to all tables in a given database.  I hoped I was close, but I'm having issues with this solution. xxnpg  xxnpg How can this be done? xxnpg  xxnpg Here's what I have: xxnpg  xxnpg EXEC sp_MSforeachtable ' xxnpg     declare @tblname varchar(255); xxnpg     SET @tblname =  PARSENAME(\"?\",1); xxnpg  xxnpg     if not exists (select column_name from INFORMATION_SCHEMA.columns  xxnpg                    where table_name = @tb...   \n",
       "128752                                                                                                                                              xxqbs why did new zealand soldiers go to world war 1? xxqbe xxans  The military history of New Zealand during World War I began in August 1914 when Great Britain declared war on Germany at the start of the First World War , the New Zealand government followed without hesitation , despite its geographic isolation and small population . It was believed at the time that any declaration of war by the United Kingdom automatically included New Zealand .   xxane   \n",
       "156442  xxqbs identify the demographic groups that made up the new reagan coalition? xxqbe xxans    VOTER GROUPS AND THE PRESIDENTIAL VOTE , 1980 AND 1976       Size   ' 80 Carter   ' 80 Reagan   ' 80 Anderson   ' 76 Carter   ' 76 Ford     Party                 Democratic   43   66   26   6   77   22     Independent   23   30   54   12   43   54     Republican   28   11   84     9   90     Ideology                 Liberal   18   57   27   11   70   26     Moderate   51   42   48   8   51   48     Conservative   31   23   71     29   70     Race                 Black   10   82   14     82   16     ...   \n",
       "29089   xxqts Factorial Algorithms in different languages xxqte xxqbs I want to see all the different ways you can come up with, for a factorial subroutine, or program. The hope is that anyone can come here and see if they might want to learn a new language. xxnpg  xxnpg Ideas: xxnpg  xxnpg  xxnpg Procedural xxnpg Functional xxnpg Object Oriented xxnpg One liners xxnpg Obfuscated xxnpg Oddball xxnpg Bad Code xxnpg Polyglot xxnpg  xxnpg  xxnpg Basically I want to see an example, of different ways of writing an algorithm, and what they would look like in different languages. xxnpg  xxnpg Please limi...   \n",
       "170018                                                                                                                                                                                                                                                                                                                                                                                                   xxqbs where does the last name polanco originate from? xxqbe xxans  Polanco is a Spanish surname originating from the municipality of Polanco , Cantabria in Spain . Notable people with the surname include :   xxane   \n",
       "130324  xxqbs history of garden of the gods colorado springs? xxqbe xxans  The Garden of the Gods ' red rock formations were created during a geological upheaval along a natural fault line millions of years ago . Archaeological evidence shows that prehistoric people visited Garden of the Gods about 1330 BC . At about 250 BC , Native American people camped in the park ; they are believed to have been attracted to wildlife and plant life in the area and used overhangs created by the rocks for shelter . Many native peoples have reported a connection to Garden of the Gods , including Apache , Cheyenne...   \n",
       "129605           xxqbs who does miss rabbit's voice on peppa pig? xxqbe xxans  Sarah Ann Kennedy is a British voice actress best known for providing the voices of Miss Rabbit and Mummy Rabbit in the children 's animated series Peppa Pig , Nanny Plum in the children 's animated series Ben & Holly 's Little Kingdom and Dolly Pond in Pond Life . She is also a writer and animation director and the creator of Crapston Villas , an animated soap opera for Channel 4 in 1996 -- 1998 . She has also written for Hit Entertainment and Peppa Pig , and is a lecturer at the University of Central Lancashire .   xxane   \n",
       "107547  xxqts li:hover - is it possible to change language of text? xxqte xxqbs A bit of a weird one,  xxnpg  xxnpg I know some of you might ask why, but I was wondering if you could change the language of some links once the user hovers over them? xxnpg  xxnpg nav li:hover { xxnpg    **change language here** xxnpg } xxnpg  xxnpg  xxnpg I was actually looking to convert English to Japanese, I'm assuming this isn't done with CSS, anyone have any ideas on how I'd go about this? xxnpg  xxnpg thanks xxnpg  xxqbe xxans You can do it with javascript, but a CSS only implementation could be like so: xxnpg...   \n",
       "156549                                                                                                                                                                                                                                                    xxqbs who is the president of the senate in nigeria? xxqbe xxans  The President of the Senate is the presiding officer of the Senate of Nigeria , elected by its membership . The Senate President is second in line for succession to the Nigerian presidency , after the Vice President of Nigeria . The current President of the Senate is Bukola Saraki .   xxane   \n",
       "133627  xxqbs when is a medical student considered a doctor? xxqbe xxans  Upon successful completion of medical school , students are granted the title of Doctor of Medicine ( M.D. ) or Doctor of Osteopathic Medicine ( D.O. ) . Residency training , which is a supervised training period of three to seven years ( usually incorporating the 1st year internship ) typically completed for specific areas of specialty . Physicians who sub-specialize or who desire more supervised experience may complete a fellowship , which is an additional one to four years of supervised training in their area of expertise...   \n",
       "184100                                                                                                                                                                                                           xxqbs who played violet in saved by the bell? xxqbe xxans  Screech does eventually end up with a girlfriend , Violet Anne Bickerstaff ( played by the then unknown Tori Spelling ) , and dates her for several episodes , even managing to win back the support of her upper - class parents after losing it on a disastrous dinner date . Violet is then never seen again , without any explanation .   xxane   \n",
       "109927  xxqbs last briton to reach mens finals at wimbledon? xxqbe xxans    Year   Best British Finish   Player   Last Opponent   Score in last match     1968   Fourth round   Mark Cox   Rod Laver   9 - 7 , 5 - 7 , 6 - 2 , 6 - 0     1969   Fourth round   Robert Wilson   Tom Okker   11 - 9 , 6 - 4 , 6 - 2     1970   Semi-final   Roger Taylor   Ken Rosewall   6 - 3 , 4 - 6 , 6 - 3 , 6 - 3     1971   Third round   Gerald Battrick   John Newcombe   6 - 4 , 6 - 4 , 6 - 4     1972   Third round   John Paish   Alex Metreveli   7 - 5 , 6 - 3 , 3 - 6 , 6 - 4     1973   Semi-final   Roger Taylor   Jan Kodeš...   \n",
       "\n",
       "             source  char_count  \n",
       "115117        tf2qa         921  \n",
       "23261       wiki103       68081  \n",
       "27841       wiki103       10414  \n",
       "67891   stacksample        1633  \n",
       "128752        tf2qa         459  \n",
       "156442        tf2qa        2606  \n",
       "29089   stacksample        1644  \n",
       "170018        tf2qa         214  \n",
       "130324        tf2qa         671  \n",
       "129605        tf2qa         590  \n",
       "107547  stacksample        1038  \n",
       "156549        tf2qa         357  \n",
       "133627        tf2qa         606  \n",
       "184100        tf2qa         398  \n",
       "109927        tf2qa        5223  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import date\n",
    "import os\n",
    "fn = f'data/lm_data_{date.today()}.csv'\n",
    "\n",
    "dfs = [wiki_fin_df, ss_fin, tf2qa_fin]\n",
    "final_data = pd.concat(dfs)\n",
    "final_data.reset_index(inplace=True, drop=True)\n",
    "final_data.to_csv(fn, sep=\"\\t\", encoding='utf-8')\n",
    "\n",
    "final_data.to_feather(f'data/lm_data_{date.today()}.ftr')\n",
    "\n",
    "print(f'Total rows : {len(final_data)}')\n",
    "print(f'Total character count : {final_data.char_count.sum()}')\n",
    "print(f'NaNs in doc column: {final_data.isna().doc.sum() / len(final_data)}')\n",
    "statinfo = os.stat(fn)\n",
    "print(f'File size is {statinfo.st_size/1000000000}GB')\n",
    "print()\n",
    "print(final_data.groupby('source').sum() / final_data.char_count.sum())\n",
    "print()\n",
    "print(fn)\n",
    "print()\n",
    "\n",
    "final_data.sample(100).head(15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
